{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47547ca5",
   "metadata": {},
   "source": [
    "## Dataframe and Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be513200",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "773dce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_1      1\n",
      "row_2      2\n",
      "row_3      3\n",
      "row_4      4\n",
      "row_5    5.3\n",
      "Name: pd_Series, dtype: string\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Series based on array\n",
    "series_from_list = pd.Series(data=[1, 2, 3, 4, 5.3],\n",
    "                             index=['row_1', 'row_2', 'row_3', 'row_4', 'row_5'],\n",
    "                             dtype='string',\n",
    "                             name='pd_Series'\n",
    "                             )\n",
    "\n",
    "print(series_from_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90121714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_3      4.0\n",
      "row_4      5.0\n",
      "row_100    NaN\n",
      "Name: pd_Series, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dict_array = {\n",
    "    'row_1': 2,\n",
    "    'row_2': 3,\n",
    "    'row_3': 4,\n",
    "    'row_4': 5,\n",
    "    'row_5': 6\n",
    "}\n",
    "\n",
    "# Series based on dict\n",
    "series_from_dict = pd.Series(dict_array,\n",
    "                             index=['row_3', 'row_4', 'row_100'],\n",
    "                             dtype=int,\n",
    "                             name='pd_Series'\n",
    "                             )\n",
    "print(series_from_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e81fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  [  1   2   3 100   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20]\n",
      "Copy [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n"
     ]
    }
   ],
   "source": [
    "# Copy Series\n",
    "np_array = np.arange(1, 21)\n",
    "series_from_np_array = pd.Series(np_array,\n",
    "                                 copy=False\n",
    "                                 )\n",
    "\n",
    "series_from_np_array.iloc[3] = 100\n",
    "\n",
    "print(\"Original: \", np_array)\n",
    "\n",
    "np_array_2 = np.arange(1, 16)\n",
    "series_from_np_array_2 = pd.Series(np_array_2,\n",
    "                                   copy=True)\n",
    "\n",
    "series_from_np_array_2.iloc[3] = 200\n",
    "\n",
    "print(\"Copy\", np_array_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c14a3670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_2    2\n",
      "row_5    5\n",
      "row_1    1\n",
      "Name: pd_Series_1, dtype: string\n"
     ]
    }
   ],
   "source": [
    "# Series based on other series\n",
    "series_list = pd.Series(data=[1, 2, 3, 4, 5],\n",
    "                        index=['row_1', 'row_2', 'row_3', 'row_4', 'row_5'],\n",
    "                        dtype='string',\n",
    "                        name='pd_Series_1'\n",
    "                        )\n",
    "\n",
    "series_from_series = pd.Series(data=series_list,\n",
    "                               index=['row_2', 'row_5', 'row_1'])\n",
    "\n",
    "print(series_from_series)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162908bd",
   "metadata": {},
   "source": [
    "### DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e5f38cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col3  col4  col1\n",
      "row_1   9.0  13.0   1.0\n",
      "row_2  10.0  14.0   2.0\n",
      "row_3  11.0  15.0   3.0\n",
      "row_4  12.0  16.0   4.0\n"
     ]
    }
   ],
   "source": [
    "dict_array = {\n",
    "    'col1': [1, 2, 3, 4],\n",
    "    'col2': [5, 6, 7, 8],\n",
    "    'col3': [9, 10, 11, 12],\n",
    "    'col4': [13, 14, 15, 16]\n",
    "}\n",
    "# DataFrame based on dict\n",
    "dateframe_from_dict = pd.DataFrame(\n",
    "    data=dict_array,\n",
    "    index=['row_1', 'row_2', 'row_3', 'row_4'],\n",
    "    columns=['col3', 'col4', 'col1'],\n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "print(dateframe_from_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5f95593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2   3   4\n",
      "0   1   2  100   4   5\n",
      "1   6   7  100   9  10\n",
      "2  11  12  100  14  15\n",
      "3  16  17  100  19  20\n",
      "[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20]]\n"
     ]
    }
   ],
   "source": [
    "# DataFrame based on numpy array WITH COPY PARAM\n",
    "np_array = [\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [6, 7, 8, 9, 10],\n",
    "    [11, 12, 13, 14, 15],\n",
    "    [16, 17, 18, 19, 20]\n",
    "]\n",
    "\n",
    "# DateFrame based on numpy array\n",
    "df_1 = pd.DataFrame(data=np_array,\n",
    "                    copy=True)\n",
    "df_1.iloc[:, 2] = 100\n",
    "\n",
    "print(df_1)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a9799b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1  col2\n",
      "row_1   2.0   NaN\n",
      "row_7   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "dict_array = {\n",
    "    'row_1': 2,\n",
    "    'row_2': 3,\n",
    "    'row_3': 4,\n",
    "    'row_4': 5,\n",
    "    'row_5': 6\n",
    "}\n",
    "\n",
    "array = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "series_1 = pd.Series(dict_array)\n",
    "series_2 = pd.Series(array, index=['row_3', 'row_4', 'row_5', 'row_6', 'row_9'])\n",
    "\n",
    "df = pd.DataFrame(data={'col1': series_1, 'col2': series_2},\n",
    "                  index=['row_1', 'row_7'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851b9253",
   "metadata": {},
   "source": [
    "## Read and Write to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef66b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id            city               category_name    price  \\\n",
      "0  dbe73ad6e4b5       Волгоград      Детская одежда и обувь      NaN   \n",
      "1  2e11806abe57     Нижняя Тура                  Велосипеды   3000.0   \n",
      "2  0b850bbebb10          Бердск               Аудио и видео  15000.0   \n",
      "3  5f1d5c3ce0da         Саратов             Бытовая техника   4500.0   \n",
      "4  23e2d97bfc7f         Бузулук  Товары для детей и игрушки   4900.0   \n",
      "5  c2a632af2602  Ростов-на-Дону      Ремонт и строительство    500.0   \n",
      "6  b239811ad530        Оренбург                    Ноутбуки  20990.0   \n",
      "7  d85fa02e6341     Калининград                    Телефоны    990.0   \n",
      "8  ae6586719bec     Новосибирск       Товары для компьютера   1200.0   \n",
      "9  30ad26d633ef       Полесской      Детская одежда и обувь    400.0   \n",
      "\n",
      "  activation_date user_type  year  month  day  \n",
      "0      2017-04-18   Private  2017      4   18  \n",
      "1      2017-04-16   Private  2017      4   16  \n",
      "2      2017-04-17   Private  2017      4   17  \n",
      "3      2017-04-17   Private  2017      4   17  \n",
      "4      2017-04-15   Private  2017      4   15  \n",
      "5      2017-04-12   Private  2017      4   12  \n",
      "6      2017-04-17      Shop  2017      4   17  \n",
      "7      2017-04-18      Shop  2017      4   18  \n",
      "8      2017-04-18   Company  2017      4   18  \n",
      "9      2017-04-12   Private  2017      4   12  \n",
      "  user_id;city;category_name;price;activation_date;user_type;year;month;day\n",
      "0  dbe73ad6e4b5;Волгоград;Детская одежда и обувь;...                       \n",
      "1  2e11806abe57;Нижняя Тура;Велосипеды;3000.0;201...                       \n",
      "2  0b850bbebb10;Бердск;Аудио и видео;15000.0;2017...                       \n",
      "3  5f1d53ce0da;Саратов;Бытовая техника;4500.0;201...                       \n",
      "4  23e2d97bfc7f;Бузулук;Товары для детей и игрушк...                       \n",
      "5  c2a632af2602;Ростов-на-Дону;Ремонт и строитель...                       \n",
      "6  b239811ad530;Оренбург;Ноутбуки;20990.0;2017-04...                       \n",
      "7  d85fa02e6341;Калининград;Телефоны;990.0;2017-0...                       \n",
      "8  ae6586719bec;Новосибирск;Товары для компьютера...                       \n",
      "9  30ad26d633ef;Полевской;Детская одежда и обувь;...                       \n"
     ]
    }
   ],
   "source": [
    "# With default sep ,\n",
    "df_1 = pd.read_csv('content/avito_data.csv')\n",
    "print(df_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4cc6eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id            city               category_name    price  \\\n",
      "0  dbe73ad6e4b5       Волгоград      Детская одежда и обувь      NaN   \n",
      "1  2e11806abe57     Нижняя Тура                  Велосипеды   3000.0   \n",
      "2  0b850bbebb10          Бердск               Аудио и видео  15000.0   \n",
      "3   5f1d53ce0da         Саратов             Бытовая техника   4500.0   \n",
      "4  23e2d97bfc7f         Бузулук  Товары для детей и игрушки   4900.0   \n",
      "5  c2a632af2602  Ростов-на-Дону      Ремонт и строительство    500.0   \n",
      "6  b239811ad530        Оренбург                    Ноутбуки  20990.0   \n",
      "7  d85fa02e6341     Калининград                    Телефоны    990.0   \n",
      "8  ae6586719bec     Новосибирск       Товары для компьютера   1200.0   \n",
      "9  30ad26d633ef       Полевской      Детская одежда и обувь    400.0   \n",
      "\n",
      "  activation_date user_type  year  month  day  \n",
      "0      2017-04-18   Private  2017      4   18  \n",
      "1      2017-04-16   Private  2017      4   16  \n",
      "2      2017-04-17   Private  2017      4   17  \n",
      "3      2017-04-17   Private  2017      4   17  \n",
      "4      2017-04-15   Private  2017      4   15  \n",
      "5      2017-04-12   Private  2017      4   12  \n",
      "6      2017-04-17      Shop  2017      4   17  \n",
      "7      2017-04-18      Shop  2017      4   18  \n",
      "8      2017-04-18   Company  2017      4   18  \n",
      "9      2017-04-12   Private  2017      4   12  \n"
     ]
    }
   ],
   "source": [
    "# With sep ;\n",
    "df_2 = pd.read_csv('content/avito_sep.csv',\n",
    "                   sep=';')\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db1bf7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               user_id               category_name    price  \\\n",
      "user_type city                                                                \n",
      "Private   Волгоград       dbe73ad6e4b5      Детская одежда и обувь      NaN   \n",
      "          Нижняя Тура     2e11806abe57                  Велосипеды   3000.0   \n",
      "          Бердск          0b850bbebb10               Аудио и видео  15000.0   \n",
      "          Саратов          5f1d53ce0da             Бытовая техника   4500.0   \n",
      "          Бузулук         23e2d97bfc7f  Товары для детей и игрушки   4900.0   \n",
      "          Ростов-на-Дону  c2a632af2602      Ремонт и строительство    500.0   \n",
      "Shop      Оренбург        b239811ad530                    Ноутбуки  20990.0   \n",
      "          Калининград     d85fa02e6341                    Телефоны    990.0   \n",
      "Company   Новосибирск     ae6586719bec       Товары для компьютера   1200.0   \n",
      "Private   Полевской       30ad26d633ef      Детская одежда и обувь    400.0   \n",
      "\n",
      "                         activation_date  year  month  day  \n",
      "user_type city                                              \n",
      "Private   Волгоград           2017-04-18  2017      4   18  \n",
      "          Нижняя Тура         2017-04-16  2017      4   16  \n",
      "          Бердск              2017-04-17  2017      4   17  \n",
      "          Саратов             2017-04-17  2017      4   17  \n",
      "          Бузулук             2017-04-15  2017      4   15  \n",
      "          Ростов-на-Дону      2017-04-12  2017      4   12  \n",
      "Shop      Оренбург            2017-04-17  2017      4   17  \n",
      "          Калининград         2017-04-18  2017      4   18  \n",
      "Company   Новосибирск         2017-04-18  2017      4   18  \n",
      "Private   Полевской           2017-04-12  2017      4   12  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_index_col = pd.read_csv('content/avito_sep.csv',\n",
    "                           sep=';',\n",
    "                           index_col=['user_type', 'city']\n",
    "                           )\n",
    "\n",
    "print(df_index_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb1f7a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     user_id    price activation_date\n",
      "city                                                 \n",
      "Волгоград       dbe73ad6e4b5      NaN      2017-04-18\n",
      "Нижняя Тура     2e11806abe57   3000.0      2017-04-16\n",
      "Бердск          0b850bbebb10  15000.0      2017-04-17\n",
      "Саратов          5f1d53ce0da   4500.0      2017-04-17\n",
      "Бузулук         23e2d97bfc7f   4900.0      2017-04-15\n",
      "Ростов-на-Дону  c2a632af2602    500.0      2017-04-12\n",
      "Оренбург        b239811ad530  20990.0      2017-04-17\n",
      "Калининград     d85fa02e6341    990.0      2017-04-18\n",
      "Новосибирск     ae6586719bec   1200.0      2017-04-18\n",
      "Полевской       30ad26d633ef    400.0      2017-04-12\n"
     ]
    }
   ],
   "source": [
    "df_usecols = pd.read_csv('content/avito_sep.csv',\n",
    "                         sep=';',\n",
    "                         index_col=['city'],\n",
    "                         usecols=['user_id', 'city', 'price', 'activation_date']\n",
    "                         )\n",
    "\n",
    "print(df_usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcfe87d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             city\n",
      "0       Волгоград\n",
      "1     Нижняя Тура\n",
      "2          Бердск\n",
      "3         Саратов\n",
      "4         Бузулук\n",
      "5  Ростов-на-Дону\n",
      "6        Оренбург\n",
      "7     Калининград\n",
      "8     Новосибирск\n",
      "9       Полевской\n"
     ]
    }
   ],
   "source": [
    "# test argument Squeeze - return Series if only one column is parsed\n",
    "df_squeeze = pd.read_csv('content/avito_sep.csv',\n",
    "                         sep=';',\n",
    "                         usecols=['city'],\n",
    "                         )\n",
    "\n",
    "df_squeeze_city = df_squeeze['city']\n",
    "print(df_squeeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b212038c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   user_id          10 non-null     object \n",
      " 1   city             10 non-null     object \n",
      " 2   price            9 non-null      float64\n",
      " 3   activation_date  10 non-null     object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 452.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   user_id          10 non-null     string  \n",
      " 1   city             10 non-null     category\n",
      " 2   price            9 non-null      float64 \n",
      " 3   activation_date  10 non-null     object  \n",
      "dtypes: category(1), float64(1), object(1), string(1)\n",
      "memory usage: 762.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('content/avito_sep.csv',\n",
    "                 sep=';',\n",
    "                 usecols=['user_id', 'city', 'price', 'activation_date'],\n",
    "                 )\n",
    "\n",
    "df.info()\n",
    "\n",
    "df1 = pd.read_csv('content/avito_sep.csv',\n",
    "                  sep=';',\n",
    "                  usecols=['user_id', 'city', 'price', 'activation_date'],\n",
    "                  dtype={'city': 'category', 'user_id': 'string'}\n",
    "                  )\n",
    "\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e010c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id         city               category_name    price  \\\n",
      "0  dbe73ad6e4b5    Волгоград      Детская одежда и обувь      NaN   \n",
      "1  2e11806abe57  Нижняя Тура                  Велосипеды   3000.0   \n",
      "2  0b850bbebb10       Бердск               Аудио и видео  15000.0   \n",
      "3   5f1d53ce0da      Саратов             Бытовая техника   4500.0   \n",
      "4  23e2d97bfc7f      Бузулук  Товары для детей и игрушки   4900.0   \n",
      "\n",
      "  activation_date user_type  year  month  day  \n",
      "0      2017-04-18   Private  2017      4   18  \n",
      "1      2017-04-16   Private  2017      4   16  \n",
      "2      2017-04-17   Private  2017      4   17  \n",
      "3      2017-04-17   Private  2017      4   17  \n",
      "4      2017-04-15   Private  2017      4   15  \n"
     ]
    }
   ],
   "source": [
    "# Argument n_rows\n",
    "df_nrows = pd.read_csv('content/avito_sep.csv',\n",
    "                       sep=';',\n",
    "                       nrows=5)\n",
    "print(df_nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6dd182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   user_id          10 non-null     object        \n",
      " 1   city             10 non-null     object        \n",
      " 2   category_name    10 non-null     object        \n",
      " 3   price            9 non-null      object        \n",
      " 4   activation_date  10 non-null     datetime64[ns]\n",
      " 5   user_type        10 non-null     object        \n",
      " 6   year             10 non-null     int64         \n",
      " 7   month            10 non-null     int64         \n",
      " 8   day              10 non-null     int64         \n",
      "dtypes: datetime64[ns](1), int64(3), object(5)\n",
      "memory usage: 852.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ht/tyf5jl1s1zq2068m9z0n2fnr0000gn/T/ipykernel_69371/3519602427.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_parse_dates = pd.read_csv('content/avito_sep.csv',\n",
      "/var/folders/ht/tyf5jl1s1zq2068m9z0n2fnr0000gn/T/ipykernel_69371/3519602427.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_parse_dates = pd.read_csv('content/avito_sep.csv',\n"
     ]
    }
   ],
   "source": [
    "# Arguments parse_dates=...\n",
    "df_parse_dates = pd.read_csv('content/avito_sep.csv',\n",
    "                             sep=';',\n",
    "                             parse_dates=['activation_date', 'price', 'category_name'])\n",
    "\n",
    "df_parse_dates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5712e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   year_month_day   10 non-null     datetime64[ns]\n",
      " 1   user_id          10 non-null     object        \n",
      " 2   city             10 non-null     object        \n",
      " 3   category_name    10 non-null     object        \n",
      " 4   price            9 non-null      float64       \n",
      " 5   activation_date  10 non-null     datetime64[ns]\n",
      " 6   user_type        10 non-null     object        \n",
      "dtypes: datetime64[ns](2), float64(1), object(4)\n",
      "memory usage: 692.0+ bytes\n",
      "None\n",
      "  year_month_day       user_id            city               category_name  \\\n",
      "0     2017-04-18  dbe73ad6e4b5       Волгоград      Детская одежда и обувь   \n",
      "1     2017-04-16  2e11806abe57     Нижняя Тура                  Велосипеды   \n",
      "2     2017-04-17  0b850bbebb10          Бердск               Аудио и видео   \n",
      "3     2017-04-17   5f1d53ce0da         Саратов             Бытовая техника   \n",
      "4     2017-04-15  23e2d97bfc7f         Бузулук  Товары для детей и игрушки   \n",
      "5     2017-04-12  c2a632af2602  Ростов-на-Дону      Ремонт и строительство   \n",
      "6     2017-04-17  b239811ad530        Оренбург                    Ноутбуки   \n",
      "7     2017-04-18  d85fa02e6341     Калининград                    Телефоны   \n",
      "8     2017-04-18  ae6586719bec     Новосибирск       Товары для компьютера   \n",
      "9     2017-04-12  30ad26d633ef       Полевской      Детская одежда и обувь   \n",
      "\n",
      "     price activation_date user_type  \n",
      "0      NaN      2017-04-18   Private  \n",
      "1   3000.0      2017-04-16   Private  \n",
      "2  15000.0      2017-04-17   Private  \n",
      "3   4500.0      2017-04-17   Private  \n",
      "4   4900.0      2017-04-15   Private  \n",
      "5    500.0      2017-04-12   Private  \n",
      "6  20990.0      2017-04-17      Shop  \n",
      "7    990.0      2017-04-18      Shop  \n",
      "8   1200.0      2017-04-18   Company  \n",
      "9    400.0      2017-04-12   Private  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ht/tyf5jl1s1zq2068m9z0n2fnr0000gn/T/ipykernel_69371/264410319.py:1: FutureWarning: Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated. Combine the desired columns with pd.to_datetime after parsing instead.\n",
      "  df_parse_dates = pd.read_csv('content/avito_sep.csv',\n",
      "/var/folders/ht/tyf5jl1s1zq2068m9z0n2fnr0000gn/T/ipykernel_69371/264410319.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_parse_dates = pd.read_csv('content/avito_sep.csv',\n"
     ]
    }
   ],
   "source": [
    "df_parse_dates = pd.read_csv('content/avito_sep.csv',\n",
    "                             sep=';',\n",
    "                            parse_dates=[['year', 'month', 'day'], 'activation_date', 'category_name']\n",
    ")\n",
    "\n",
    "print(df_parse_dates.info())\n",
    "print(df_parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f1f08c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   year_month_day   10 non-null     datetime64[ns]\n",
      " 1   user_id          10 non-null     object        \n",
      " 2   city             10 non-null     object        \n",
      " 3   category_name    10 non-null     object        \n",
      " 4   price            9 non-null      float64       \n",
      " 5   activation_date  10 non-null     datetime64[ns]\n",
      " 6   user_type        10 non-null     object        \n",
      "dtypes: datetime64[ns](2), float64(1), object(4)\n",
      "memory usage: 692.0+ bytes\n",
      "None\n",
      "       data0      data1       user_id            city  \\\n",
      "0 2017-04-18 2017-04-18  dbe73ad6e4b5       Волгоград   \n",
      "1 2017-04-16 2017-04-16  2e11806abe57     Нижняя Тура   \n",
      "2 2017-04-17 2017-04-17  0b850bbebb10          Бердск   \n",
      "3 2017-04-17 2017-04-17   5f1d53ce0da         Саратов   \n",
      "4 2017-04-15 2017-04-15  23e2d97bfc7f         Бузулук   \n",
      "5 2017-04-12 2017-04-12  c2a632af2602  Ростов-на-Дону   \n",
      "6 2017-04-17 2017-04-17  b239811ad530        Оренбург   \n",
      "7 2017-04-18 2017-04-18  d85fa02e6341     Калининград   \n",
      "8 2017-04-18 2017-04-18  ae6586719bec     Новосибирск   \n",
      "9 2017-04-12 2017-04-12  30ad26d633ef       Полевской   \n",
      "\n",
      "                category_name    price user_type  \n",
      "0      Детская одежда и обувь      NaN   Private  \n",
      "1                  Велосипеды   3000.0   Private  \n",
      "2               Аудио и видео  15000.0   Private  \n",
      "3             Бытовая техника   4500.0   Private  \n",
      "4  Товары для детей и игрушки   4900.0   Private  \n",
      "5      Ремонт и строительство    500.0   Private  \n",
      "6                    Ноутбуки  20990.0      Shop  \n",
      "7                    Телефоны    990.0      Shop  \n",
      "8       Товары для компьютера   1200.0   Company  \n",
      "9      Детская одежда и обувь    400.0   Private  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ht/tyf5jl1s1zq2068m9z0n2fnr0000gn/T/ipykernel_69371/1122905000.py:1: FutureWarning: Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated. Combine the desired columns with pd.to_datetime after parsing instead.\n",
      "  df_parse_dates1 = pd.read_csv('content/avito_sep.csv',\n"
     ]
    }
   ],
   "source": [
    "df_parse_dates1 = pd.read_csv('content/avito_sep.csv',\n",
    "                             sep=';',\n",
    "                            parse_dates={\n",
    "                                'data0': ['activation_date'],\n",
    "                                'data1': ['year', 'month', 'day']\n",
    "                                }\n",
    ")\n",
    "\n",
    "print(df_parse_dates.info())\n",
    "print(df_parse_dates1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "372d7dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       data1       user_id            city               category_name  \\\n",
      "0 2017-04-18  dbe73ad6e4b5       Волгоград      Детская одежда и обувь   \n",
      "1 2017-04-16  2e11806abe57     Нижняя Тура                  Велосипеды   \n",
      "2 2017-04-17  0b850bbebb10          Бердск               Аудио и видео   \n",
      "3 2017-04-17   5f1d53ce0da         Саратов             Бытовая техника   \n",
      "4 2017-04-15  23e2d97bfc7f         Бузулук  Товары для детей и игрушки   \n",
      "5 2017-04-12  c2a632af2602  Ростов-на-Дону      Ремонт и строительство   \n",
      "6 2017-04-17  b239811ad530        Оренбург                    Ноутбуки   \n",
      "7 2017-04-18  d85fa02e6341     Калининград                    Телефоны   \n",
      "8 2017-04-18  ae6586719bec     Новосибирск       Товары для компьютера   \n",
      "9 2017-04-12  30ad26d633ef       Полевской      Детская одежда и обувь   \n",
      "\n",
      "     price activation_date user_type  year month day  \n",
      "0      NaN      2017-04-18   Private  2017     4  18  \n",
      "1   3000.0      2017-04-16   Private  2017     4  16  \n",
      "2  15000.0      2017-04-17   Private  2017     4  17  \n",
      "3   4500.0      2017-04-17   Private  2017     4  17  \n",
      "4   4900.0      2017-04-15   Private  2017     4  15  \n",
      "5    500.0      2017-04-12   Private  2017     4  12  \n",
      "6  20990.0      2017-04-17      Shop  2017     4  17  \n",
      "7    990.0      2017-04-18      Shop  2017     4  18  \n",
      "8   1200.0      2017-04-18   Company  2017     4  18  \n",
      "9    400.0      2017-04-12   Private  2017     4  12  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ht/tyf5jl1s1zq2068m9z0n2fnr0000gn/T/ipykernel_69371/610042448.py:2: FutureWarning: The 'keep_date_col' keyword in pd.read_csv is deprecated and will be removed in a future version. Explicitly remove unwanted columns after parsing instead.\n",
      "  df_parse_dates1 = pd.read_csv('content/avito_sep.csv',\n",
      "/var/folders/ht/tyf5jl1s1zq2068m9z0n2fnr0000gn/T/ipykernel_69371/610042448.py:2: FutureWarning: Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated. Combine the desired columns with pd.to_datetime after parsing instead.\n",
      "  df_parse_dates1 = pd.read_csv('content/avito_sep.csv',\n"
     ]
    }
   ],
   "source": [
    "# Argument keep_date_col and encoding\n",
    "df_parse_dates1 = pd.read_csv('content/avito_sep.csv',\n",
    "                             sep=';',\n",
    "                             keep_date_col=True,\n",
    "                            parse_dates={\n",
    "                                'data1': ['year', 'month', 'day'],\n",
    "                                },\n",
    "                            encoding='utf8'\n",
    ")\n",
    "\n",
    "print(df_parse_dates1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b79cf",
   "metadata": {},
   "source": [
    "### Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "73886df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('content/avito_data.csv')\n",
    "\n",
    "# Save file\n",
    "df.to_csv('content/avito_copy.csv', sep=';')\n",
    "\n",
    "# Save columns\n",
    "df.to_csv('content/avito_copy.csv',\n",
    "          sep=';',\n",
    "          columns=['city', 'price']\n",
    "          )\n",
    "\n",
    "# Argument header\n",
    "df.to_csv('content/avito_copy.csv',\n",
    "          sep=';',\n",
    "          columns=['city', 'price'],\n",
    "          header=['city_copy', 'price_copy']\n",
    "          )\n",
    "\n",
    "#Argument index\n",
    "df.to_csv('content/avito_copy.csv',\n",
    "          sep=';',\n",
    "          index=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5ad49a",
   "metadata": {},
   "source": [
    "## Read and Write SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "74ee7811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        city               category_name    price  \\\n",
      "user_id                                                             \n",
      "dbe73ad6e4b5       Волгоград      Детская одежда и обувь      NaN   \n",
      "2e11806abe57     Нижняя Тура                  Велосипеды   3000.0   \n",
      "0b850bbebb10          Бердск               Аудио и видео  15000.0   \n",
      "5f1d5c3ce0da         Саратов             Бытовая техника   4500.0   \n",
      "23e2d97bfc7f         Бузулук  Товары для детей и игрушки   4900.0   \n",
      "c2a632af2602  Ростов-на-Дону      Ремонт и строительство    500.0   \n",
      "b239811ad530        Оренбург                    Ноутбуки  20990.0   \n",
      "d85fa02e6341     Калининград                    Телефоны    990.0   \n",
      "ae6586719bec     Новосибирск       Товары для компьютера   1200.0   \n",
      "30ad26d633ef       Полесской      Детская одежда и обувь    400.0   \n",
      "\n",
      "             activation_date user_type  year  month  day  \n",
      "user_id                                                   \n",
      "dbe73ad6e4b5      2017-04-18   Private  2017      4   18  \n",
      "2e11806abe57      2017-04-16   Private  2017      4   16  \n",
      "0b850bbebb10      2017-04-17   Private  2017      4   17  \n",
      "5f1d5c3ce0da      2017-04-17   Private  2017      4   17  \n",
      "23e2d97bfc7f      2017-04-15   Private  2017      4   15  \n",
      "c2a632af2602      2017-04-12   Private  2017      4   12  \n",
      "b239811ad530      2017-04-17      Shop  2017      4   17  \n",
      "d85fa02e6341      2017-04-18      Shop  2017      4   18  \n",
      "ae6586719bec      2017-04-18   Company  2017      4   18  \n",
      "30ad26d633ef      2017-04-12   Private  2017      4   12  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3 as sq\n",
    "\n",
    "def create_table(db='avito_data.db', path='content/avito_data.csv', name_table='avito'):\n",
    "    con = sq.connect(db)\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    df.to_sql(name_table, con, if_exists='replace', index=False)\n",
    "    con.close()\n",
    "    \n",
    "create_table()\n",
    "\n",
    "sql_request = '''SELECT * FROM avito'''\n",
    "\n",
    "df = pd.read_csv('content/avito_data.csv')\n",
    "\n",
    "with sq.connect('avito_data.db') as con:\n",
    "    df_sql = pd.read_sql(sql=sql_request,\n",
    "                         con=con,\n",
    "                         index_col=['user_id'],\n",
    "                         parse_dates=['activation'],\n",
    "                         )\n",
    "    \n",
    "print(df_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333552da",
   "metadata": {},
   "source": [
    "## Indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2de3705b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_1\n",
      "0  1        1\n",
      "1  2        1\n",
      "2  3        1\n",
      "3  4        1\n",
      "4  5        1\n",
      "5  6        1\n",
      "Name: col_3, dtype: int64\n",
      "         col_3  col_4  NEW_COL\n",
      "  col_1                       \n",
      "0 1          1     18       19\n",
      "1 2          1     19       20\n",
      "2 3          1     20       21\n",
      "3 4          1     21       22\n",
      "4 5          1     22       23\n",
      "5 6          1     23       24\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'col_1': [1, 2, 3, 4, 5, 6],\n",
    "    'col_2': [7, 19, 8, 9, 10, 11],\n",
    "    'col_3': [12, 13, 14, 15, 16, 17],\n",
    "    'col_4': [18, 19, 20, 21, 22, 23]\n",
    "})\n",
    "\n",
    "df.set_index(['col_1', 'col_2'], inplace=True, append=True)\n",
    "df.reset_index('col_2', inplace=True, drop=True)\n",
    "# print(df)\n",
    "df['col_3'] = 1\n",
    "df['NEW_COL'] = df['col_3'] + df['col_4']\n",
    "# del df['col_1']\n",
    "print(df['col_3'])\n",
    "print(df[['col_3', 'col_4', 'NEW_COL']])\n",
    "\n",
    "# print(df.col_1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb10bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['q', 'w', 'q', 'i', 't', 'u', 'i', 'z'], dtype='object', name='rows')\n"
     ]
    }
   ],
   "source": [
    "list_index = list('qwqituiz')\n",
    "\n",
    "index_data_1 = pd.Index(list_index,\n",
    "                      name='rows')\n",
    "\n",
    "print(index_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d2b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols  col_1  col_2  col_3\n",
      "rows                     \n",
      "q         1      9     17\n",
      "w         2     10     18\n",
      "q         3     11     19\n",
      "i         4     12     20\n",
      "t         5     13     21\n",
      "u         6     14     22\n",
      "i         7     15     23\n",
      "z         8     16     24\n"
     ]
    }
   ],
   "source": [
    "columns_data = pd.Index(['col_1', 'col_2', 'col_3'],\n",
    "                        name='cols'\n",
    "                        )\n",
    "df_data = pd.DataFrame(data={\n",
    "    'col_1': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'col_2': [9, 10, 11, 12, 13, 14, 15, 16],\n",
    "    'col_3': [17, 18, 19, 20, 21, 22, 23, 24]\n",
    "},\n",
    "    index=index_data_1,\n",
    "    columns=columns_data\n",
    "    )\n",
    "\n",
    "print(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d3f07b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     c_0  c_1   c_2   c_3   c_4   c_5   c_6   c_7   c_8   c_9  ...   c_90  \\\n",
      "0      0    0     0     0     0     0     0     0     0     0  ...      0   \n",
      "1      0    1     2     3     4     5     6     7     8     9  ...     90   \n",
      "2      0    2     4     6     8    10    12    14    16    18  ...    180   \n",
      "3      0    3     6     9    12    15    18    21    24    27  ...    270   \n",
      "4      0    4     8    12    16    20    24    28    32    36  ...    360   \n",
      "..   ...  ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
      "995    0  995  1990  2985  3980  4975  5970  6965  7960  8955  ...  89550   \n",
      "996    0  996  1992  2988  3984  4980  5976  6972  7968  8964  ...  89640   \n",
      "997    0  997  1994  2991  3988  4985  5982  6979  7976  8973  ...  89730   \n",
      "998    0  998  1996  2994  3992  4990  5988  6986  7984  8982  ...  89820   \n",
      "999    0  999  1998  2997  3996  4995  5994  6993  7992  8991  ...  89910   \n",
      "\n",
      "      c_91   c_92   c_93   c_94   c_95   c_96   c_97   c_98   c_99  \n",
      "0        0      0      0      0      0      0      0      0      0  \n",
      "1       91     92     93     94     95     96     97     98     99  \n",
      "2      182    184    186    188    190    192    194    196    198  \n",
      "3      273    276    279    282    285    288    291    294    297  \n",
      "4      364    368    372    376    380    384    388    392    396  \n",
      "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "995  90545  91540  92535  93530  94525  95520  96515  97510  98505  \n",
      "996  90636  91632  92628  93624  94620  95616  96612  97608  98604  \n",
      "997  90727  91724  92721  93718  94715  95712  96709  97706  98703  \n",
      "998  90818  91816  92814  93812  94810  95808  96806  97804  98802  \n",
      "999  90909  91908  92907  93906  94905  95904  96903  97902  98901  \n",
      "\n",
      "[1000 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({f'c_{i}': np.arange(1000)*i for i in range(100)})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ba680f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n",
      "\n",
      "<bound method IndexOpsMixin.to_numpy of Index(['c_0', 'c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'c_6', 'c_7', 'c_8', 'c_9',\n",
      "       'c_10', 'c_11', 'c_12', 'c_13', 'c_14', 'c_15', 'c_16', 'c_17', 'c_18',\n",
      "       'c_19', 'c_20', 'c_21', 'c_22', 'c_23', 'c_24', 'c_25', 'c_26', 'c_27',\n",
      "       'c_28', 'c_29', 'c_30', 'c_31', 'c_32', 'c_33', 'c_34', 'c_35', 'c_36',\n",
      "       'c_37', 'c_38', 'c_39', 'c_40', 'c_41', 'c_42', 'c_43', 'c_44', 'c_45',\n",
      "       'c_46', 'c_47', 'c_48', 'c_49', 'c_50', 'c_51', 'c_52', 'c_53', 'c_54',\n",
      "       'c_55', 'c_56', 'c_57', 'c_58', 'c_59', 'c_60', 'c_61', 'c_62', 'c_63',\n",
      "       'c_64', 'c_65', 'c_66', 'c_67', 'c_68', 'c_69', 'c_70', 'c_71', 'c_72',\n",
      "       'c_73', 'c_74', 'c_75', 'c_76', 'c_77', 'c_78', 'c_79', 'c_80', 'c_81',\n",
      "       'c_82', 'c_83', 'c_84', 'c_85', 'c_86', 'c_87', 'c_88', 'c_89', 'c_90',\n",
      "       'c_91', 'c_92', 'c_93', 'c_94', 'c_95', 'c_96', 'c_97', 'c_98', 'c_99'],\n",
      "      dtype='object')>\n"
     ]
    }
   ],
   "source": [
    "# Get indexes and columns\n",
    "index = df.index\n",
    "columns = df.columns\n",
    "\n",
    "index.to_list()\n",
    "columns.to_numpy()\n",
    "\n",
    "\n",
    "print(index.to_list(), columns.to_numpy, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eae421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['q', 'w', 'i', 't', 'u', 'z'], dtype='object', name='rows')\n",
      "6\n",
      "False\n",
      "[False False  True False False False  True False]\n",
      "rows cols\n"
     ]
    }
   ],
   "source": [
    "list_index = list('qwqituiz')\n",
    "\n",
    "index_data_1 = pd.Index(list_index,\n",
    "                      name='rows')\n",
    "\n",
    "\n",
    "df_data = pd.DataFrame(data={\n",
    "    'col_1': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'col_2': [9, 10, 11, 12, 13, 14, 15, 16],\n",
    "    'col_3': [17, 18, 19, 20, 21, 22, 23, 24]\n",
    "},\n",
    "    index=index_data_1,\n",
    "    columns=columns_data\n",
    "    )\n",
    "\n",
    "\n",
    "index_data = df_data.index\n",
    "\n",
    "print(index_data.unique())\n",
    "print(index_data.nunique())\n",
    "print(index_data.is_unique)\n",
    "print(index_data.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e4191e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows_new cols_new\n",
      "cols_new  col_11  col_22  col_33\n",
      "rows_new                        \n",
      "q              1       9      17\n",
      "w              2      10      18\n",
      "q              3      11      19\n",
      "i              4      12      20\n",
      "t              5      13      21\n",
      "u              6      14      22\n",
      "i              7      15      23\n",
      "z              8      16      24\n",
      "cols_new  col_1  col_2  col_3\n",
      "rows_new                     \n",
      "Q             1      9     17\n",
      "W             2     10     18\n",
      "Q             3     11     19\n",
      "I             4     12     20\n",
      "T             5     13     21\n",
      "U             6     14     22\n",
      "I             7     15     23\n",
      "Z             8     16     24\n"
     ]
    }
   ],
   "source": [
    "print(index_data.name, columns_data.name)\n",
    "index_data.name = 'rows_new'\n",
    "columns_data.name = 'cols_new'\n",
    "\n",
    "df_data_renamed = df_data.rename(columns={\n",
    "    'col_1': 'col_11',\n",
    "    'col_2': 'col_22',\n",
    "    'col_3': 'col_33',\n",
    "})\n",
    "\n",
    "\n",
    "df_data.rename(str.upper,\n",
    "                axis=0,\n",
    "                inplace=True)\n",
    "\n",
    "print(df_data_renamed)\n",
    "print(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4c611700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "1.0  0\n",
      "NaN  1\n",
      "3.0  2\n",
      "NaN  3\n",
      "5.0  4\n",
      "True\n",
      "[False  True False  True False]\n",
      "Index([1.0, 3.0, 5.0], dtype='float64')\n"
     ]
    }
   ],
   "source": [
    "# NONE's in indexes\n",
    "\n",
    "index = pd.Index([1, np.nan, 3, np.nan, 5])\n",
    "\n",
    "df_nan = pd.DataFrame(data=np.arange(5), index=index)\n",
    "\n",
    "print(df_nan)\n",
    "print(df_nan.index.hasnans)\n",
    "print(df_nan.index.isna())\n",
    "print(df_nan.index.dropna())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f042f2bb",
   "metadata": {},
   "source": [
    "# MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a138935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
